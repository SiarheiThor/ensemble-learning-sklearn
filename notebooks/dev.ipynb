{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "def preprocess_image(image, target_size=(28, 28)):\n",
    "    \"\"\"Preprocess the input image to match MNIST data format.\"\"\"\n",
    "    # Convert to grayscale\n",
    "    image = image.convert('L')\n",
    "    # Resize image to match model's expected input\n",
    "    #image = resize(np.array(image), target_size, anti_aliasing=True)\n",
    "    # Normalize pixel values\n",
    "    image = image / 255.0\n",
    "    # Reshape for the model\n",
    "    image = image.reshape(1, 28*28)\n",
    "    return image\n",
    "\n",
    "def crop_to_digit_preprocess(image_path):\n",
    "    # Read the image in grayscale\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Apply Gaussian Blurring\n",
    "    blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "    # Apply Thresholding or Edge Detection\n",
    "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Assume the largest contour is the digit\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "        # Crop the image around the bounding rectangle of the digit\n",
    "        digit = img[y:y+h, x:x+w]\n",
    "\n",
    "        # Resize the cropped digit to 28x28 pixels\n",
    "        digit_resized = cv2.resize(digit, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Normalize pixel values to be in the range [0, 1]\n",
    "        digit_normalized = digit_resized / 255.0\n",
    "\n",
    "        # Ensure the digit is in the correct shape (1, 28, 28) for MNIST-like format\n",
    "        digit_reshaped = digit_normalized.reshape(1, 28, 28)\n",
    "        return digit_reshaped\n",
    "    else:\n",
    "        return None  # No digit found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'convert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#image = Image.open(image_path)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m digit_image \u001b[38;5;241m=\u001b[39m crop_to_digit(image_path)\n\u001b[0;32m----> 4\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdigit_image\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[0;34m(image, target_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess the input image to match MNIST data format.\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Convert to grayscale\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Resize image to match model's expected input\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#image = resize(np.array(image), target_size, anti_aliasing=True)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Normalize pixel values\u001b[39;00m\n\u001b[1;32m     15\u001b[0m image \u001b[38;5;241m=\u001b[39m image \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'convert'"
     ]
    }
   ],
   "source": [
    "image_path = '/home/thor_01/Documents/EC/ensemble-learning-sklearn/notebooks/IMG_2127.jpg'\n",
    "#image = Image.open(image_path)\n",
    "digit_image = crop_to_digit(image_path)\n",
    "#sample = preprocess_image(digit_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[220, 217, 219, ..., 204, 204, 203],\n",
       "       [221, 220, 220, ..., 206, 204, 203],\n",
       "       [221, 221, 221, ..., 206, 204, 203],\n",
       "       ...,\n",
       "       [221, 222, 224, ..., 210, 206, 204],\n",
       "       [217, 224, 226, ..., 209, 205, 202],\n",
       "       [218, 220, 221, ..., 207, 203, 200]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 199356 into shape (28,28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mdigit_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgaussian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 199356 into shape (28,28)"
     ]
    }
   ],
   "source": [
    "plt.imshow(digit_image.reshape(28, 28), interpolation=\"gaussian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def crop_to_digit(image_path):\n",
    "    # Read the image in grayscale\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Apply Gaussian Blurring\n",
    "    blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "    # Apply Thresholding or Edge Detection\n",
    "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Assume the largest contour is the digit\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "        # Crop and return the image around the bounding rectangle of the digit\n",
    "        digit = img[y:y+h, x:x+w]\n",
    "        return digit\n",
    "    else:\n",
    "        return None  # No digit found\n",
    "\n",
    "# Example usage\n",
    "digit_image = crop_to_digit(image_path)\n",
    "\n",
    "if digit_image is not None:\n",
    "    cv2.imshow(\"Cropped Digit\", digit_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
